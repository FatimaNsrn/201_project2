{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449,
          "referenced_widgets": [
            "2a228e9e1f0443c2bd928cdf1443ef6c",
            "4e5906e94f7b47e29a9d899a098d0e14",
            "8ba71ee26d8e4ef7a73853c19e0a1791",
            "0a77ffe3026a4e05890b859481251d40",
            "9a39d16f3c414d28b7057d2a506be081",
            "0162701eca8f4565b406d885d3683647",
            "f1b437df2e704048b1ac3d42f52bec1c",
            "9962b5cd36ea483ba924c9b06849cc49",
            "15412e74384946bc8a772583e8038051",
            "5f8d38938d6f4f8e8de5bce395e4d664",
            "2af934dd1c644c3eb2a48fd210995043",
            "e473f6e68075494f986d546b8d8d2a48",
            "707a2a962a864a9f9a5436a27fa2c51a",
            "2020ac7157274ada933d0e7d569bac11",
            "fbe221d73e504298a07e87b40edd86ea",
            "728fc3700796458f8a1c30acc995c21b",
            "b4a70bba89e245148312ba3c1c5bd840",
            "29f1e96610504c73bd22d5be2fd6611e",
            "8f819a921b4f40a593e9511dde3b6352",
            "e2b4bd68c72f4e89b8dc37e50c3fe37f",
            "4246ff005e274ed3b8fbc6ed06cc51b3",
            "c64ebf35dd0a4adc90bfb947deb94e83",
            "77f2191f56d143afac9542a2a920b928",
            "817f8473fc9240aeb32a39def3ace5fb",
            "5b2d3fd54225485bb0f654f01ff4cb11",
            "e5d9628bab9a4bee93e6c8a7df2e5a77",
            "1d1868b0b4ce468981729c7a150d4715",
            "3a9fd37320ad4df89d29f32c807710f9",
            "8b8bb9bafecd4f59982bb1053cb393c8",
            "742e143f63f74968a80bf8b5c72c57c9",
            "150e827973b3417c8016b7d85575f8ee",
            "6ad41832c3b541d0b7385b3f868c00d8",
            "1c3928154e2e497d90e47e25143b72e4",
            "af79db10654b4af7a49bcbc99b0da688",
            "004857acc5fe4715b54530d0f54bfb83",
            "34fb26a171144c19b527e840e5f6b8fc",
            "82ba890ded2a4eada54c541e7693a9ec",
            "98e0460b443a40d5bde765fffdc45404",
            "0e5e35c861734d488f25e6f30cb3bb38",
            "1722b15ca57c4e0f9b4edd08a3238a7b",
            "929b6cd180974fef880a2f778f0b195b",
            "c782290c1225410cb25b686073befdbe",
            "5c220726854848e987a4593efac7a827",
            "9484bc5777554bf5a2d07eab3ad5f547",
            "3a55a2820f0945a4aa9b83b5fea63337",
            "fe21b0d1b8d74c379022898725809c18",
            "c5d58b4259914cddbd3276e02cb21037",
            "ba053a50ed284a4eb8ced2519c785ce2",
            "47b8f0fc1ea0481881aec7a9cb27453f",
            "cf11d51528ff41d39922ccdcfadcb14c",
            "5e9474dcd66048b9ac9afa5a41574a11",
            "8e7f16c2fea74e82a16a9924049c32d2",
            "b897c8fa61b248fb8cd11996acabfc5e",
            "5c7565ceb833499d841ce993def06226",
            "e7afeb980ecd4f6483f28de2aab4a3dc",
            "3ed5e5b0b3bb426880fe425b8bf2e07f",
            "57c5d72faf5b43a18cba9caa19b7c2d1",
            "f1566f002ac14bb1a44b6e9ad653cb96",
            "5d7d76221e704dbf9be2bb3dbe5df798",
            "0687585c0cef4c4abc070b88d6089e9c",
            "13fa70a68f814f60bdaed7ed46cd334c",
            "5fc7c28f92344e30999464dfb0313441",
            "bcc39863b4374546914b028eb5a5dc96",
            "43a8901880c743d7b99831185f215314",
            "c8cb13672d5d4df6969297bbbc368cac",
            "4c526c0b5fc34e9da0790bf38d700758",
            "def375328594486f96c872b19fa715bb",
            "e3e848d807974e7ea4250ca869b7a77c",
            "851dcfb6a8cb4bbda9c446f88f512f82",
            "885e8c74110744eaa8b783ba392a8b15",
            "865bd318c0b64912abe9d23db4324368",
            "fe30c7dfdc054e6b91a7cbc4e9c719b0",
            "bf56f4347d314708a579b7cb070a81be",
            "1ad2a6d217af4f4fb295390aa393f270",
            "64d035dd5d8844818b35596ba811acfb",
            "b318503b30364d3c8c9b6cbaab280f4f",
            "f98615aa6c174fd5a9af76520b7364b6"
          ]
        },
        "id": "hJJyiAPbU-aE",
        "outputId": "aa9f95a7-7e83-454c-ffd4-f2b16ec6f1c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00001.parquet:   0%|          | 0.00/3.31M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/validation-00000-of-00001.parquet:   0%|          | 0.00/431k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/test-00000-of-00001.parquet:   0%|          | 0.00/423k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/26384 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3296 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/3296 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"AliFartout/PEYMA-ARMAN-Mixed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds[\"train\"].column_names\n",
        "ds[\"train\"][0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpM_EHhFVYqQ",
        "outputId": "31b0064a-94a2-416e-aa7e-fe6074da2c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tokens': ['ÛŒÙˆÚ©ÙˆÙˆÛŒÚ†',\n",
              "  'Ù…ØªÙˆÙ„Ø¯',\n",
              "  'Ø¯Ø§Ù†Ù…Ø§Ø±Ú©',\n",
              "  'Ø§Ø³Øª',\n",
              "  'Ø§Ù…Ø§',\n",
              "  'ÙˆØ§Ù„Ø¯ÛŒÙ†',\n",
              "  'Ø§Ùˆ',\n",
              "  'ØµØ±Ø¨',\n",
              "  'Ù‡Ø³ØªÙ†Ø¯',\n",
              "  '.'],\n",
              " 'ner_tags': [5, 20, 1, 20, 20, 20, 20, 1, 20, 20],\n",
              " 'ner_tags_names': ['B_PER',\n",
              "  'O',\n",
              "  'B_LOC',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B_LOC',\n",
              "  'O',\n",
              "  'O']}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = ds[\"train\"]\n",
        "val_ds = ds[\"validation\"]\n",
        "test_ds = ds[\"test\"]"
      ],
      "metadata": {
        "id": "Y2GHn4a1Vdu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all unique label names\n",
        "all_labels = set()\n",
        "for sample in train_ds:\n",
        "    all_labels.update(sample[\"ner_tags_names\"])\n",
        "\n",
        "label_list = sorted(list(all_labels))\n",
        "\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "\n",
        "print(label2id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNYva9DzVgHf",
        "outputId": "56a07bc8-1341-4a16-87ae-1d21240eaf33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B_DAT': 0, 'B_EVE': 1, 'B_FAC': 2, 'B_LOC': 3, 'B_MON': 4, 'B_ORG': 5, 'B_PCT': 6, 'B_PER': 7, 'B_PRO': 8, 'B_TIM': 9, 'I_DAT': 10, 'I_EVE': 11, 'I_FAC': 12, 'I_LOC': 13, 'I_MON': 14, 'I_ORG': 15, 'I_PCT': 16, 'I_PER': 17, 'I_PRO': 18, 'I_TIM': 19, 'O': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"HooshvareLab/bert-base-parsbert-uncased\",\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "efd14cdb05e84a26a6713ff2eadd3d39",
            "91a7d07ea89640d8a8283f6e0d7469fa",
            "5cf843bee39040779c5c456f2c058b7a",
            "b5ea9a788d984d8db03dabd9c19db4e3",
            "cc15113b9fc5413a96eb35354ba3fa2a",
            "7c2a9a348eb7488e97cc981443b86c20",
            "2daa841238df41638f140ab5c56db31b",
            "1cc40c3833e2474dbb23f2948139ecc8",
            "f34985d1b0ad425eb4867fa26a193584",
            "a889cf85aaec4aa089a22499ddb63510",
            "88972c0e41db4c4187589dfbf4810823",
            "4fd2378c04b14df2aacee2371efb7fec",
            "db2f8d94da184fef8a28695f2be35eb5",
            "ceb72da7610444d89b0730e3adab0f5f",
            "b13665c963fb49c89bb249394bac0316",
            "e154bd51f93e4cb5b403cdebe38d0456",
            "6ca0beeba30145aeb8fcba8d61722e96",
            "1ba0ff6934474d1aae9b39254da7fad3",
            "317758ee80844ee0b2d9fa8e76bd41de",
            "299a33f7781f49ccbe9697286a733105",
            "4d30e51f1fdb4403ab944718d60f0038",
            "bc11f5cf74cb4632a1e1f2c48f65dd02",
            "7fb6bf1dcd8646f4b3d5cdb089fca2be",
            "0e07f2744591499e822e8c89e121751c",
            "953e430b6ce04ff59f81600cbb6346f2",
            "57c1bf09f9b242938d5bd02ee806a307",
            "691ca4e4f1544bb7a6a37c717c3362cf",
            "c9ec096a4f004c11abdc272dab4351c4",
            "1da58c202f6444f48bf2cdddf87c8cc3",
            "d2209c834d2e4fe482f5ed04e521ffa5",
            "7b67864c94aa492fba921ae9a52f692d",
            "cd9bfe0c66dc4f54a9043170f0ef0465",
            "b90b65eec3b347b3b2cdec48c24e6f5d"
          ]
        },
        "id": "vjjlkY3tVkq1",
        "outputId": "3a520837-9410-4e74-8c6a-bfb30dc3fc3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/434 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at HooshvareLab/bert-base-parsbert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def ner_collate_fn(batch, tokenizer, max_len=128):\n",
        "    input_ids_list = []\n",
        "    attention_masks_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    for sample in batch:\n",
        "        tokens = sample[\"tokens\"]\n",
        "        labels = sample[\"ner_tags\"]\n",
        "\n",
        "        encoding = tokenizer(\n",
        "            tokens,\n",
        "            is_split_into_words=True,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
        "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
        "\n",
        "        word_ids = encoding.word_ids(0)\n",
        "\n",
        "        aligned_labels = []\n",
        "        prev_word = None\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                aligned_labels.append(-100)\n",
        "            elif word_idx != prev_word:\n",
        "                aligned_labels.append(labels[word_idx])\n",
        "            else:\n",
        "                aligned_labels.append(-100)\n",
        "            prev_word = word_idx\n",
        "\n",
        "        input_ids_list.append(input_ids)\n",
        "        attention_masks_list.append(attention_mask)\n",
        "        labels_list.append(torch.tensor(aligned_labels))\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": pad_sequence(input_ids_list, batch_first=True, padding_value=tokenizer.pad_token_id),\n",
        "        \"attention_mask\": pad_sequence(attention_masks_list, batch_first=True, padding_value=0),\n",
        "        \"labels\": pad_sequence(labels_list, batch_first=True, padding_value=-100),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "v1nWSpAfVn3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
        "                          collate_fn=lambda b: ner_collate_fn(b, tokenizer))\n",
        "\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
        "                        collate_fn=lambda b: ner_collate_fn(b, tokenizer))\n",
        "\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False,\n",
        "                         collate_fn=lambda b: ner_collate_fn(b, tokenizer))\n"
      ],
      "metadata": {
        "id": "mxXVNABUVrnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "epochs = 3\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
        "\n",
        "total_steps = len(train_loader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(0.1 * total_steps),\n",
        "    num_training_steps=total_steps\n",
        ")\n"
      ],
      "metadata": {
        "id": "p-TJji6NVvFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float(\"inf\")\n",
        "patience = 2\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nðŸ”µ Epoch {epoch+1}/{epochs}\")\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=batch[\"input_ids\"].to(device),\n",
        "            attention_mask=batch[\"attention_mask\"].to(device),\n",
        "            labels=batch[\"labels\"].to(device)\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train = train_loss / len(train_loader)\n",
        "\n",
        "    # VALIDATION\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            outputs = model(\n",
        "                input_ids=batch[\"input_ids\"].to(device),\n",
        "                attention_mask=batch[\"attention_mask\"].to(device),\n",
        "                labels=batch[\"labels\"].to(device)\n",
        "            )\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "    avg_val = val_loss / len(val_loader)\n",
        "    print(f\"Train Loss: {avg_train:.4f} | Val Loss: {avg_val:.4f}\")\n",
        "\n",
        "    # EARLY STOPPING\n",
        "    if avg_val < best_val_loss:\n",
        "        best_val_loss = avg_val\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"best_ner_model.pt\")\n",
        "        print(\"ðŸ’¾ Saved best model!\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"â›” Early stopping triggered!\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16lOpB8XV23_",
        "outputId": "2d0256d7-6614-4a03-890c-57a520f34ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”µ Epoch 1/3\n",
            "Train Loss: 0.1888 | Val Loss: 0.0568\n",
            "ðŸ’¾ Saved best model!\n",
            "\n",
            "ðŸ”µ Epoch 2/3\n",
            "Train Loss: 0.0313 | Val Loss: 0.0347\n",
            "ðŸ’¾ Saved best model!\n",
            "\n",
            "ðŸ”µ Epoch 3/3\n",
            "Train Loss: 0.0091 | Val Loss: 0.0347\n",
            "ðŸ’¾ Saved best model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "import torch\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"HooshvareLab/bert-base-parsbert-uncased\",\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(\"best_ner_model.pt\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVua7veye9LL",
        "outputId": "1eb12f83-83f5-43ce-9e38-bb9dadd72973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at HooshvareLab/bert-base-parsbert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(100000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=21, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp5y4hxyfIWb",
        "outputId": "1bc05e03-54b2-4831-d05b-5574b731c2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from seqeval) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=d296a57711ab82adb2302e24f2c2231417117dc47671f05fdd0b3c9c7ca6c280\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "\n",
        "for batch in test_loader:\n",
        "    input_ids = batch[\"input_ids\"].to(device)\n",
        "    attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "    labels = batch[\"labels\"].cpu().numpy()\n",
        "\n",
        "    for pred_seq, label_seq in zip(predictions, labels):\n",
        "        true_seq = []\n",
        "        pred_seq_clean = []\n",
        "\n",
        "        for p, l in zip(pred_seq, label_seq):\n",
        "            if l == -100:\n",
        "                continue  # skip subword predictions\n",
        "            true_seq.append(id2label[l])\n",
        "            pred_seq_clean.append(id2label[p])\n",
        "\n",
        "        true_labels.append(true_seq)\n",
        "        pred_labels.append(pred_seq_clean)\n"
      ],
      "metadata": {
        "id": "ipMxdYvrfNQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_labels, pred_labels, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw-UGYI1fcf4",
        "outputId": "1a80223c-0112-495e-b6e0-8e6c2bf82bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ORG seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_LOC seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_EVE seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_FAC seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_PRO seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_DAT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_DAT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_PER seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_PRO seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_PCT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_PER seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_TIM seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_MON seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ORG seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_MON seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_EVE seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_PCT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_LOC seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_FAC seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_TIM seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        _DAT     0.9331    0.9208    0.9269      1515\n",
            "        _EVE     0.9686    0.9562    0.9624      1874\n",
            "        _FAC     0.9773    0.9762    0.9768       926\n",
            "        _LOC     0.9548    0.9670    0.9609      2033\n",
            "        _MON     0.9412    0.9536    0.9474       151\n",
            "        _ORG     0.9754    0.9849    0.9801      1651\n",
            "        _PCT     0.9482    0.9714    0.9597       245\n",
            "        _PER     0.8976    0.8341    0.8647       452\n",
            "        _PRO     0.8852    0.9307    0.9074       779\n",
            "        _TIM     0.9051    0.9709    0.9368       275\n",
            "\n",
            "   micro avg     0.9497    0.9528    0.9512      9901\n",
            "   macro avg     0.9387    0.9466    0.9423      9901\n",
            "weighted avg     0.9498    0.9528    0.9512      9901\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# First, get all unique labels\n",
        "unique_labels = sorted(label_list)\n",
        "\n",
        "per_tag_metrics = []\n",
        "\n",
        "for tag in unique_labels:\n",
        "    # Collect all true/pred labels for this tag\n",
        "    y_true_tag = []\n",
        "    y_pred_tag = []\n",
        "    for t_seq, p_seq in zip(true_labels, pred_labels):\n",
        "        for t, p in zip(t_seq, p_seq):\n",
        "            if t == tag:\n",
        "                y_true_tag.append(t)\n",
        "                y_pred_tag.append(p)\n",
        "\n",
        "    # Compute metrics\n",
        "    precision = precision_score([y_true_tag], [y_pred_tag], average='macro')\n",
        "    recall = recall_score([y_true_tag], [y_pred_tag], average='macro')\n",
        "    f1 = f1_score([y_true_tag], [y_pred_tag], average='macro')\n",
        "    accuracy = sum([t==p for t,p in zip(y_true_tag, y_pred_tag)]) / len(y_true_tag)\n",
        "\n",
        "    per_tag_metrics.append({\n",
        "        \"tag\": tag,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1-score\": f1,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"support\": len(y_true_tag)\n",
        "    })\n",
        "\n",
        "# Print nicely\n",
        "print(f\"{'Tag':<6} {'Precision':>9} {'Recall':>7} {'F1-score':>9} {'Accuracy':>9} {'Support':>8}\")\n",
        "for m in per_tag_metrics:\n",
        "    print(f\"{m['tag']:<6} {m['precision']*100:9.4f} {m['recall']*100:7.4f} {m['f1-score']*100:9.4f} {m['accuracy']*100:9.4f} {m['support']:8}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHeHFd60f8qR",
        "outputId": "397355cf-8ad0-4eb7-c188-c9100ad2bb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag    Precision  Recall  F1-score  Accuracy  Support\n",
            "B_DAT    33.3333 23.8361   27.7959   71.5084      179\n",
            "B_EVE    14.2857 13.6982   13.9858   95.8874     1848\n",
            "B_FAC    50.0000 46.0784   47.9592   92.1569       51\n",
            "B_LOC    14.2857 13.8662   14.0728   97.0632     2009\n",
            "B_MON   100.0000 74.0741   85.1064   74.0741       27\n",
            "B_ORG    20.0000 19.6745   19.8359   98.3724     1536\n",
            "B_PCT    50.0000 38.8889   43.7500   77.7778       27\n",
            "B_PER    33.1276 22.8369   27.0361   68.9362      235\n",
            "B_PRO    16.6667 14.9278   15.7494   89.5669      508\n",
            "B_TIM    50.0000 47.0370   48.4733   94.0741      135\n",
            "I_DAT     0.0000  0.0000    0.0000   95.5187     2834\n",
            "I_EVE     0.0000  0.0000    0.0000   80.6452       31\n",
            "I_FAC     0.0000  0.0000    0.0000   97.9943     1047\n",
            "I_LOC     0.0000  0.0000    0.0000   78.3784       37\n",
            "I_MON   100.0000 100.0000  100.0000  100.0000      124\n",
            "I_ORG   100.0000 100.0000  100.0000  100.0000      237\n",
            "I_PCT   100.0000 100.0000  100.0000  100.0000      218\n",
            "I_PER   100.0000 100.0000  100.0000  100.0000      697\n",
            "I_PRO   100.0000 100.0000  100.0000  100.0000      271\n",
            "I_TIM   100.0000 100.0000  100.0000  100.0000      281\n",
            "O         0.0000  0.0000    0.0000   99.6832    91541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(true_labels, pred_labels)\n",
        "print(\"Accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38WOHR-hgYmV",
        "outputId": "a8fe9de0-1c4d-46c9-d535-0c15afabaf81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9921635073599492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wrong_predictions(true_labels, pred_labels, token_seqs):\n",
        "    \"\"\"\n",
        "    true_labels: list of lists of true tags\n",
        "    pred_labels: list of lists of predicted tags\n",
        "    token_seqs: list of lists of tokens (words)\n",
        "    \"\"\"\n",
        "    wrong_examples = []\n",
        "\n",
        "    for tokens, t_seq, p_seq in zip(token_seqs, true_labels, pred_labels):\n",
        "        for token, true, pred in zip(tokens, t_seq, p_seq):\n",
        "            if true != pred:\n",
        "                wrong_examples.append({\n",
        "                    \"token\": token,\n",
        "                    \"true_label\": true,\n",
        "                    \"pred_label\": pred\n",
        "                })\n",
        "\n",
        "    return wrong_examples\n"
      ],
      "metadata": {
        "id": "rl57uNJTg0Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect tokens from your test dataset\n",
        "token_seqs = [sample[\"tokens\"] for sample in test_ds]\n",
        "\n",
        "wrong_examples = get_wrong_predictions(true_labels, pred_labels, token_seqs)\n",
        "\n",
        "# Show first 10 wrong predictions\n",
        "for example in wrong_examples[:10]:\n",
        "    print(f\"Token: {example['token']:15} True: {example['true_label']:7} Pred: {example['pred_label']:7}\")\n"
      ],
      "metadata": {
        "id": "puNtWKeVg20G",
        "outputId": "11651358-f401-424e-ef2e-b3bb362e0117",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: Ø±ÙˆÛŒØ³            True: B_ORG   Pred: B_LOC  \n",
            "Token: Ø´Ù‡Ø±             True: O       Pred: B_EVE  \n",
            "Token: Ø¢Ù„ÙˆÙ…ÛŒÙ†ÛŒÙˆÙ…       True: O       Pred: B_PRO  \n",
            "Token: Ú©Ù‡Ù             True: O       Pred: B_EVE  \n",
            "Token: Ø­ØµÛŒÙ†            True: O       Pred: B_PRO  \n",
            "Token: Ø«Ø§Ù…Ù†            True: B_ORG   Pred: B_PRO  \n",
            "Token: Ø§Ù„Ø§Ø¦Ù…Ù‡          True: I_FAC   Pred: B_PRO  \n",
            "Token: (Ø¹)             True: I_FAC   Pred: B_PRO  \n",
            "Token: 17              True: B_DAT   Pred: B_PER  \n",
            "Token: Ù†Ú¯Ø§Ø±Ø®Ø§Ù†Ù‡        True: B_EVE   Pred: I_MON  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_sentence_errors(tokens, true_seq, pred_seq):\n",
        "    output = []\n",
        "    for token, true, pred in zip(tokens, true_seq, pred_seq):\n",
        "        if true != pred:\n",
        "            output.append(f\"[{token} | T:{true} P:{pred}]\")\n",
        "        else:\n",
        "            output.append(token)\n",
        "    print(\" \".join(output))\n",
        "\n",
        "# Example with first 5 test sentences\n",
        "for i in range(5):\n",
        "    show_sentence_errors(token_seqs[i], true_labels[i], pred_labels[i])\n"
      ],
      "metadata": {
        "id": "opAR7vUug6gg",
        "outputId": "ba10f4ef-ac5d-4c6f-adcb-c79db090cb64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ø±ÙˆÛŒØ³ | T:B_ORG P:B_LOC] Ùˆ ØªÙ…Ø³Ø®Ø± Ø¨Ø§ÛŒØ±Ù† Ø¨Ø®Ø§Ø·Ø± Ø¨Ø§Ø®Øª Ø¨Ù‡ Ø§ØªÙ„ØªÛŒÚ©Ùˆ ( Ø¹Ú©Ø³ ) .\n",
            "! Ø­Ø§Ù„ Ø¬Ø§ÛŒ Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ Ø¨Ø§Ù‚ÛŒ Ø§Ø³Øª Ú†Ø±Ø§ Ø¯Ø± ÙˆØ±ÙˆØ¯ÛŒ Ø§ÛŒÙ† Ø´Ù‡Ø± Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ù†ÙˆØ´ØªÙ‡\\u200cØ§Ù†Ø¯ \" Ø¨Ù‡ Ø¨Ù†Ø¯Ø±Ø¹Ø¨Ø§Ø³ [Ø´Ù‡Ø± | T:O P:B_EVE] [Ø¢Ù„ÙˆÙ…ÛŒÙ†ÛŒÙˆÙ… | T:O P:B_PRO] Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯ \"ØŸ !\n",
            "Ø¹Ø¨Ø¯Ø§Ù„Ù…Ø·Ù„Ø¨ ØŒ Ø¯Ø± Ø®ÙˆØ§Ø¨ Ù…ÛŒ\\u200cØ¨ÛŒÙ†Ø¯ ÙƒÙ‡ Ù…Ø£Ù…ÙˆØ± Ø­ÙØ± Ú†Ø§Ù‡ Ø²Ù…Ø²Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª .\n",
            "Ø§ÛŒÙ† Ù…Ù†Ø¨Ø¹ Ø§Ù…Ù†ÛŒØªÛŒ Ú©Ù‡ Ø®ÙˆØ§Ø³Øª Ù†Ø§Ù…Ø´ ÙØ§Ø´ Ù†Ø´ÙˆØ¯ ØªØ§Ú©ÛŒØ¯ Ú©Ø±Ø¯ Ø¨Ø¹Ø¯ Ø§Ø² ÙØ±Ø§Ø± Ø§ÛŒÙ† 9 Ú©ÙˆØ¯Ú© Ø§Ø² Ù†Ø¨Ø±Ø¯Ù‡Ø§ÛŒ ÙÙ„ÙˆØ¬Ù‡ ØŒ Ø¯Ø§Ø¹Ø´ Ø¢Ù†Ù‡Ø§ Ø±Ø§ Ø¨Ø§Ø²Ø¯Ø§Ø´Øª Ùˆ Ø§Ù‚Ø¯Ø§Ù… Ø¨Ù‡ Ø§Ø¹Ø¯Ø§Ù… Ø¢Ù†Ù‡Ø§ Ú©Ø±Ø¯Ù‡ Ø§Ø³Øª .\n",
            "ÙˆÛŒ ØªØ§Ú©ÛŒØ¯ Ú©Ø±Ø¯ ØªØ¹Ø±Ø¶ Ø¨Ù‡ Ø¢Ø²Ø§Ø¯ÛŒ\\u200cÙ‡Ø§ÛŒ Ø§Ø³Ø§Ø³ÛŒ Ø¯Ø± [Ú©Ù‡Ù | T:O P:B_EVE] [Ø­ØµÛŒÙ† | T:O P:B_PRO] [Ø«Ø§Ù…Ù† | T:B_ORG P:B_PRO] [Ø§Ù„Ø§Ø¦Ù…Ù‡ | T:I_FAC P:B_PRO] [(Ø¹) | T:I_FAC P:B_PRO] Ù…Ø§ÛŒÙ‡ Ø´Ø±Ù…Ø³Ø§Ø±ÛŒ Ø§Ø³Øª .\n"
          ]
        }
      ]
    }
  ]
}